{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import openai\n",
    "import tiktoken\n",
    "\n",
    "import pandas as pd\n",
    "import json\n",
    "\n",
    "from dateutil import parser as date_parser\n",
    "from unidecode import unidecode\n",
    "\n",
    "import os\n",
    "import time\n",
    "import re"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Table Generator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "class TableGenerator_JSON():  \n",
    "    SYSTEM_MSG = \"You are a retriever of facts.\"\n",
    "    \n",
    "    ROW_TEMPLATE = \"\"\"\n",
    "    We want to create a table with the detailed information about %s.\n",
    "    Columns in the table are %s.\n",
    "    %s.     \n",
    "    Retrieve a single row whose key is %s.\n",
    "    The response will be formatted as JSON dictionary shown below.\n",
    "    Pay special attention to wrap all property names and values in double quotes!\n",
    "    \n",
    "    RESPONSE FORMAT:\n",
    "    {\n",
    "        %s\n",
    "    }\n",
    "    \"\"\" \n",
    "    \n",
    "    def _norm_field(self, s):\n",
    "        s = s.lower().replace(\" \",\"_\").replace(\"-\",\"_\").replace(\".\", \"\").replace(\",\",\"_\")\\\n",
    "                .replace(\"(\", \"\").replace(\")\", \"\").replace(\":\", \"\").replace('\"','').replace(\"'\",\"\")\\\n",
    "                .replace(\"/\", \"\")\n",
    "        return re.sub('_+', '_', s)\n",
    "    \n",
    "    def _key_columns(self, keys):\n",
    "        if len(keys) == 1:\n",
    "            return \"The key column in the table is %s\" % keys[0]\n",
    "        else:\n",
    "            return \"The key columns in the table are %s\" % \", \".join(keys)\n",
    "    \n",
    "    def generate_row_prompt(self, query, keys, fields, fetched_key):        \n",
    "        for key in keys:\n",
    "            fetched_key[self._norm_field(key)] = fetched_key.pop(key)\n",
    "        \n",
    "        keys = [self._norm_field(k) for k in keys]\n",
    "        key_columns = self._key_columns(keys)    \n",
    "        \n",
    "        fields = [self._norm_field(f) for f in fields]\n",
    "        all_columns = \", \".join(fields)\n",
    "\n",
    "        key_json = []\n",
    "        fields_json = []        \n",
    "        for field in fields:\n",
    "            if field in fetched_key:\n",
    "                key_value = str(fetched_key[field]).replace('\"','')\n",
    "                key_json.append(\"%s = %s\" % (field, key_value))\n",
    "            field_value = fetched_key.get(field, field)\n",
    "            fields_json.append('\"%s\": \"%s\"' % (field, field_value))\n",
    "        \n",
    "        row_key = '(%s)' % ', '.join(key_json)\n",
    "        response_format = ', '.join(fields_json)\n",
    "        prompt = self.ROW_TEMPLATE % (query, all_columns, key_columns, row_key, response_format)        \n",
    "        return prompt \n",
    "    \n",
    "    def parse_row_response(self, response):          \n",
    "        if not response.startswith(\"{\") and \"{\" in response:\n",
    "            response = response[response.find(\"{\"):]\n",
    "\n",
    "        if not response.endswith(\"}\") and \"}\" in response:\n",
    "            response = response[:response.find(\"}\")+1]\n",
    "\n",
    "        response_json = json.loads(response)\n",
    "        return response_json\n",
    "    \n",
    "    def create_dataframe(self, rows, columns, keys, df_ref): \n",
    "        df = pd.DataFrame.from_dict(rows)  \n",
    "        columns = [self._norm_field(col) for col in columns]\n",
    "        df = df[columns]\n",
    "        df.columns = df_ref.columns\n",
    "        df = df.drop_duplicates(subset=keys)\n",
    "        return df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Experiment Runner"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ExperimentRunner():\n",
    "    openai.api_key = \"\"\n",
    "    MODEL = \"gpt-4o\"\n",
    "    NOTE = 'row_by_row_oracle_keys'\n",
    "    \n",
    "    def __init__(self, table_generator, metadata_path):\n",
    "        with open(metadata_path, \"rb\") as f:\n",
    "            self.metadata = json.load(f)\n",
    "            \n",
    "        self.table_generator = table_generator\n",
    "        self.encoding = tiktoken.get_encoding(\"cl100k_base\")\n",
    "        \n",
    "        self.result_folder = \"DATA/%s_%s_%s\" % (self.MODEL.split(\"/\")[-1].replace('-', '_'), \n",
    "                                                   self.NOTE,\n",
    "                                                   time.strftime(\"%Y%m%d-%H%M%S\"))\n",
    "        \n",
    "        print(\"Experiment result folder: %s\" % self.result_folder)\n",
    "        \n",
    "        os.makedirs(self.result_folder)\n",
    "        os.makedirs(\"%s/tables\" % self.result_folder)\n",
    "        \n",
    "        self.result = {}\n",
    "        \n",
    "    def fetch_data(self, idx):\n",
    "        task = self.metadata[idx]\n",
    "        \n",
    "        task_name = task['name']        \n",
    "        print(\"Fetching data for %s\" % task_name)\n",
    "        \n",
    "        query = task['table_title']\n",
    "        keys = task['keys']\n",
    "        columns = task['columns'] \n",
    "            \n",
    "        try:\n",
    "            df_ref = pd.read_csv(task['path'])\n",
    "            oracle_keys = df_ref[keys].to_dict('records')            \n",
    "            print(\"Fetched %d oracle key instances\" % len(oracle_keys))                       \n",
    "\n",
    "            self.result[idx] = {} \n",
    "            self.result[idx]['row_prompts'] = []\n",
    "            self.result[idx]['row_responses'] = []\n",
    "            rows = []\n",
    "            \n",
    "            for key_instance in oracle_keys:\n",
    "                try:\n",
    "                    row_prompt_i = self.table_generator.generate_row_prompt(query, keys, columns, key_instance)\n",
    "                    self.result[idx]['row_prompts'].append(row_prompt_i)\n",
    "                   \n",
    "                    result = openai.ChatCompletion.create(\n",
    "                        model=self.MODEL,\n",
    "                        messages=[{\"role\": \"system\", \"content\": self.table_generator.SYSTEM_MSG},\n",
    "                        {\"role\": \"user\", \"content\": row_prompt_i}],\n",
    "                        temperature=0)\n",
    "\n",
    "                    row_response = result[\"choices\"][0][\"message\"][\"content\"].strip()\n",
    "                    self.result[idx]['row_responses'].append(row_response)\n",
    "\n",
    "                    parsed_row_response = self.table_generator.parse_row_response(row_response)\n",
    "                    rows.append(parsed_row_response)\n",
    "                except Exception as ie:\n",
    "                    print(ie.__class__.__name__)\n",
    "                    rows_json = []\n",
    "                    fields = [self.table_generator._norm_field(col) for col in columns]\n",
    "                    for field in fields:\n",
    "                        value = key_instance.get(field, \"failed\")\n",
    "                        rows_json.append('\"%s\": \"%s\"' % (field, value))\n",
    "                    failed_row = \"{%s}\" % ', '.join(rows_json)\n",
    "                    rows.append(json.loads(failed_row))        \n",
    "            \n",
    "            df = self.table_generator.create_dataframe(rows, columns, keys, df_ref) \n",
    "\n",
    "            table_path = \"%s/tables/%s.csv\" % (self.result_folder, task_name)\n",
    "            self.result[idx]['table_path'] = table_path                \n",
    "            df.to_csv(table_path, index=False)            \n",
    "\n",
    "            print(\"Created table with %d rows\" % len(df))\n",
    "\n",
    "            return df\n",
    "        except Exception as e:  \n",
    "            print(e.__class__.__name__)\n",
    "            \n",
    "    def save_result(self):\n",
    "        with open(\"%s/result.json\" % self.result_folder, \"w\") as outfile:\n",
    "            result_json = json.dumps(self.result, indent=4)\n",
    "            outfile.write(result_json)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Experiment result folder: DATA/gpt_4o_row_by_row_oracle_keys_20240927-160338\n",
      "\n",
      "====================\n",
      "\n",
      "Table # 31\n",
      "Fetching data for classic_100_ten_years_on\n",
      "Fetched 100 oracle key instances\n",
      "Created table with 100 rows\n",
      "\n",
      "====================\n",
      "\n",
      "Table # 32\n",
      "Fetching data for udaykumar_films\n",
      "Fetched 160 oracle key instances\n",
      "Created table with 160 rows\n",
      "\n",
      "====================\n",
      "\n",
      "Table # 33\n",
      "Fetching data for fa_cup_qualifying_rounds_1999_2000\n",
      "Fetched 197 oracle key instances\n",
      "Created table with 197 rows\n",
      "\n",
      "====================\n",
      "\n",
      "Table # 34\n",
      "Fetching data for portuguese_grape_varieties\n",
      "Fetched 126 oracle key instances\n",
      "Created table with 126 rows\n",
      "\n",
      "====================\n",
      "\n",
      "Table # 35\n",
      "Fetching data for ramsar_convention_parties\n",
      "Fetched 166 oracle key instances\n",
      "Created table with 166 rows\n",
      "\n",
      "====================\n",
      "\n",
      "Table # 36\n",
      "Fetching data for guitar_hero_5_songs\n",
      "Fetched 85 oracle key instances\n",
      "Created table with 85 rows\n",
      "\n",
      "====================\n",
      "\n",
      "Table # 37\n",
      "Fetching data for south_cambridgeshire_district_council_1973_2012\n",
      "Fetched 40 oracle key instances\n",
      "Created table with 40 rows\n",
      "\n",
      "====================\n",
      "\n",
      "Table # 38\n",
      "Fetching data for dublin_maternity_hospital_mortality_rates_1784_1849\n",
      "Fetched 66 oracle key instances\n",
      "Created table with 66 rows\n",
      "\n",
      "====================\n",
      "\n",
      "Table # 39\n",
      "Fetching data for ship_launches_january_1944\n",
      "Fetched 96 oracle key instances\n",
      "Created table with 96 rows\n",
      "\n",
      "====================\n",
      "\n",
      "Table # 40\n",
      "Fetching data for uk_demographics_1960_2012\n",
      "Fetched 53 oracle key instances\n",
      "Created table with 53 rows\n",
      "\n",
      "====================\n",
      "\n",
      "Table # 41\n",
      "Fetching data for fukushima_plant_operating_history_1970_2009\n",
      "Fetched 40 oracle key instances\n",
      "Created table with 40 rows\n",
      "\n",
      "====================\n",
      "\n",
      "Table # 42\n",
      "Fetching data for new_zealand_football_results_1922_2012\n",
      "Fetched 56 oracle key instances\n",
      "Created table with 56 rows\n",
      "\n",
      "====================\n",
      "\n",
      "Table # 43\n",
      "Fetching data for jack_nicklaus_achievements_1962_2005\n",
      "Fetched 44 oracle key instances\n",
      "Created table with 44 rows\n",
      "\n",
      "====================\n",
      "\n",
      "Table # 44\n",
      "Fetching data for bond_credit_rating_1981_2008\n",
      "Fetched 28 oracle key instances\n",
      "Created table with 28 rows\n",
      "\n",
      "====================\n",
      "\n",
      "Table # 45\n",
      "Fetching data for baltimore_oreoles_2012\n",
      "Fetched 26 oracle key instances\n",
      "Created table with 26 rows\n",
      "\n",
      "====================\n",
      "\n",
      "Table # 46\n",
      "Fetching data for david_robinson_40_pts_games\n",
      "Fetched 23 oracle key instances\n",
      "Created table with 23 rows\n",
      "\n",
      "====================\n",
      "\n",
      "Table # 47\n",
      "Fetching data for latin_american_migration_to_uk_1997_2008\n",
      "Fetched 19 oracle key instances\n",
      "Created table with 19 rows\n",
      "\n",
      "====================\n",
      "\n",
      "Table # 48\n",
      "Fetching data for european_countries_gdp_2007_2012\n",
      "Fetched 47 oracle key instances\n",
      "Created table with 47 rows\n",
      "\n",
      "====================\n",
      "\n",
      "Table # 49\n",
      "Fetching data for royal_dulton_figurines_HN4100_HN4199\n",
      "Fetched 59 oracle key instances\n",
      "Created table with 59 rows\n",
      "\n",
      "====================\n",
      "\n",
      "Table # 50\n",
      "Fetching data for adaalat_episodes_2012\n",
      "Fetched 100 oracle key instances\n",
      "Created table with 100 rows\n",
      "\n",
      "====================\n",
      "\n",
      "Table # 51\n",
      "Fetching data for viktoria_plzen_1993_2012\n",
      "Fetched 20 oracle key instances\n",
      "Created table with 20 rows\n",
      "\n",
      "====================\n",
      "\n",
      "Table # 52\n",
      "Fetching data for just_dance_kids_2_tracks\n",
      "Fetched 39 oracle key instances\n",
      "Created table with 39 rows\n",
      "\n",
      "====================\n",
      "\n",
      "Table # 53\n",
      "Fetching data for cross_country_junior_women_1996\n",
      "Fetched 115 oracle key instances\n",
      "Created table with 115 rows\n",
      "\n",
      "====================\n",
      "\n",
      "Table # 54\n",
      "Fetching data for metropolitan_opera_us_premieres\n",
      "Fetched 99 oracle key instances\n",
      "Created table with 99 rows\n",
      "\n",
      "====================\n",
      "\n",
      "Table # 55\n",
      "Fetching data for kasparov_kramnik_1993_2004\n",
      "Fetched 49 oracle key instances\n",
      "Created table with 49 rows\n",
      "\n",
      "====================\n",
      "\n",
      "Table # 56\n",
      "Fetching data for decathlon_top50_1999\n",
      "Fetched 50 oracle key instances\n",
      "Created table with 50 rows\n",
      "\n",
      "====================\n",
      "\n",
      "Table # 57\n",
      "Fetching data for minor_planets_152601_152700\n",
      "Fetched 100 oracle key instances\n",
      "Created table with 100 rows\n",
      "\n",
      "====================\n",
      "\n",
      "Table # 58\n",
      "Fetching data for two_and_a_half_men_season_7\n",
      "Fetched 22 oracle key instances\n",
      "Created table with 22 rows\n",
      "\n",
      "====================\n",
      "\n",
      "Table # 59\n",
      "Fetching data for moesha_season_7\n",
      "Fetched 26 oracle key instances\n",
      "Created table with 26 rows\n",
      "\n",
      "====================\n",
      "\n",
      "Table # 60\n",
      "Fetching data for miss_new_york_usa_delegates_2012\n",
      "Fetched 142 oracle key instances\n",
      "Created table with 142 rows\n",
      "\n",
      "====================\n",
      "\n",
      "Table # 61\n",
      "Fetching data for clint_dolezel_stats_1995_2008\n",
      "Fetched 13 oracle key instances\n",
      "Created table with 13 rows\n",
      "\n",
      "====================\n",
      "\n"
     ]
    }
   ],
   "source": [
    " tg = TableGenerator_JSON()\n",
    "\n",
    "runner = ExperimentRunner(tg, metadata_path=\"DATA/benchmark/cfg.json\")\n",
    "\n",
    "print(\"\\n====================\\n\")\n",
    "\n",
    "for i in range(30,61):\n",
    "    print(\"Table # %d\" % (i+1))\n",
    "    idx = \"%d\" % i\n",
    "    table = runner.fetch_data(idx)\n",
    "    print(\"\\n====================\\n\")\n",
    "    \n",
    "runner.save_result()  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
